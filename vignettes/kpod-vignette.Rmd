---
title: "Introduction to kpodcluster"
output: html_notebook
---


# {.tabset .tabset-pills}

## Why k-POD?

### K-means drawback

One of the most common clustering algorithms used by data scientists today is k-means clustering. K-means clustering is an easy-to-follow and fast-to-execute algorithm to fulfill basic clustering needs with a simple function call, `kmeans()`. 

However, k-means suffers one major drawback : it requires a __complete__ data set without missing entries. Realistically, in many data analysis scenarios, data sets tend to have missing entries due to errors in data collection or data cleaning. When attempting to perform k-means clustering on data sets with missing entries, one faces the following options before proceeding to the clustering:

***
1. eliminate the observations(rows) with missing features(columns) from the data set, then perform k-means clustering on partial data;

2. impute the missing values using a certain algorithm, then perform k-means clustering on imputed data;

3. contact the data collecting agency for clarification on the missing values.

***

### K-POD prevails

All these options are either computationally expensive, or lacking competence in producing the ideal clustering results. The `kpodcluster` package's `kpod()` offers an simple, reliable and fast alternative to resolve the difficulties of applying k-means clustering on __incomplete__ data. 

In addition to resolving the incomplete data issue, `kpod()` users have the default option to use the __k-means++__ algorithm to initialize centers, in order to address the potentially inconsistent clustering results caused by randomized initial centers in k-means clustering.

***

## Example Data

### makeData()

`kpodclustr` includes a `makeData()` function that generates data sets with missing entries under user's customization. It produces a list object consisting of 3 objects:

***

- `Orig` : the complete data set.

- `Missing` : the incomplete data set. 

- `truth` : the cluster assignment matrix. 

***

For the remainder of the demonstration of `kpodcluster`, we will use the example data generated from the following code. 

```{r exampleData}
library(kpodclustr)
testData <- kpodclustr::makeData(p = 2, n = 20, k = 5, sigma = 0.25, missing = 0.3, seed = 1991); testData
```

### Parameters for this specific example: 

***

- n = 20 (20 observations)

- p = 2 (each observation has 2 features)

- k = 5 (5 clusters, 5 centroids) 

- sigma = 0.25 (scalar of variance for noise around the centroids) 

- missing = 0.3 (missingness, or percentage of missing entries. 20 * 2 * 0.3 = 12 missing entries)

- seed = 1991 (random seed for reproducibility)

***

### Process of `makeData()`:

***

1. Generate centroid matrix, `M`, with `k`*`p` random samples from standard normal distribution.

2. Generate assignment matrix, `assignment`, with `n` ramdom samples from 1 to `k` with replacement.

3. Initialize complete data matrix, `X`, using `M` and `assignment`, so that each observation of `X` has the same features as its assigned cluster centroid.

4. Add noise to each value in the initialized `X` with standard normal distribution multiplying a deviation scalar of `sigma`. 

5. Initialize incomplete data matrix, `X_missing`, as a copy of `X`.

6. Generate indices of missing entries, `missing_ix`, with `n`\*`p`\*`missing` random samples from 1 to `n`\*`p` without replacement.

7. Replace values in `X_missing` at `missing_ix` indices with `NA`.

8. Return `X`, `X_missing`, and `assignment`.

***

## Usage of k-POD 

### Usage of k-POD

The __key function__ in `kpodclustr` is `kpod()`. `kpod()` delegates to the rest of the functions in `kpodclustr`. Like `kmeans()`, `kpod()` has a data set parameter, and a number-of-clusters parameter. The difference is that `kpod()` takes in a incomplete data set. The following code and output displays the usage of `kpod()` on the second object in the Example Data list, `X_missing`.

```{r kpodUsage}
kpodclustr::kpod(X = testData[[2]], k = 5)
```

### Returned items explained

***

- `cluster` : The final cluster assignment matrix containing a sequence of cluster labels corresponding to each observation.

- `cluster_list` : A list of cluster assignment matrices throughout all iterations until clustering converges or `kpod()` reaches maximum iterations. If clustering converges, the last two cluster assignment matrices should be the same. `cluster` is the last object in `cluster_list`.

- `obj_vals` : The calculated value of the k-means objective function throughout iterations. The __k-means objective function__ measures the sum of all "intra-cluster variance", or "within-cluster sum of square", which is the sum of squared distance between each observation and its cluster center for all observations. K-means aims to minimize this intra-cluster variance. As shown in the example output, the objective function value decreases as k-POD clustering progresses. 

- `fit` : The final measurement of fit of cluster assignment after clustering commences. The closer the fit is to 1, the better the fit. The fit equation is explained below this section.

- `fit_list` : A list of measurement of fit of cluster assignment throughout all iterations until clustering converges or `kpod()` reaches maximum iterations. `fit` is the last object in `fit_list`. As shown in the example output, the fit increases and approaches 1 as k-POD clustering progresses.

***

### The `fit` equation

***
<center> $fit = 1 - ((\sum withinss) / (totss))$ </center>
***

As mentioned in explanation of `obj_vals`, "withinss" means "within-cluster sum of square", which is the sum of squared distance between each observation and its cluster center for each cluster. Taking the sum of "withinss" yields the sum of squared distance between each observation and its cluster center for all clusters.

There is also "betweenss", meaning "between-cluster sum of square" or "inter-cluster variance", is the sum of squared distance between all cluster centroids. 

"totss", meaning "total sum of square", is the sum of squared distance between each observation and the global center(the center of all observations). 

Identity: <center> $totss = \sum withinss + betweenss$ </center>

***

## k-means vs k-POD

"The k-POD method builds upon k-means clustering to provide a simple and quick alternative to clustering missing data that works even _when the missingness mechanism is unknown, when external information is unavailable, and when there is significant missingness in the data_."

### Performance comparison {.tabset}

#### Data 1

Data 1: p = 2, n = 20, k = 3, sigma = 0.25, seed = 1991

```{r data1means, echo=FALSE}
library(ggplot2)
data1 <- kpodclustr::makeData(p = 2, n = 20, k = 3, sigma = 0.25, missing = 0.1, seed = 1991)
X1991 <- data1[[1]]
km1991 <- kmeans(X1991,3)
g1991means <- ggplot(data = as.data.frame(X1991), mapping = aes(x=X1991[,1],y=X1991[,2], color=factor(km1991$cluster))) + geom_point() + theme(legend.position = "none") 
# g1991means <- g1991means + geom_point(data = as.data.frame(km1991$centers), mapping = aes(x=km1991$centers[,1],y=km1991$centers[,2], color = "black",size = 3))
g1991means <- g1991means + labs(x = "Feature 1", y = "Feature 2", title = "Data 1, k-means with complete data")
g1991means 
```

```{r data1pod0.1, echo=FALSE}
Xm1991 <- data1[[2]]
kp1991 <- kpodclustr::kpod(Xm1991,3)
g1991pod <- ggplot(data = as.data.frame(X1991), mapping = aes(x=X1991[,1],y=X1991[,2], color=factor(kp1991$cluster))) + geom_point() + theme(legend.position = "none")
g1991pod <- g1991pod + labs(x = "Feature 1", y = "Feature 2", title = "Data 1, k-POD with 10% missingness")
g1991pod
```


```{r data1pod0.2, echo=FALSE}
data1 <- kpodclustr::makeData(p = 2, n = 20, k = 3, sigma = 0.25, missing = 0.2, seed = 1991)

Xm1991 <- data1[[2]]
kp1991 <- kpodclustr::kpod(Xm1991,3)
g1991pod <- ggplot(data = as.data.frame(X1991), mapping = aes(x=X1991[,1],y=X1991[,2], color=factor(kp1991$cluster))) + geom_point() + theme(legend.position = "none")
g1991pod <- g1991pod + labs(x = "Feature 1", y = "Feature 2", title = "Data 1, k-POD with 20% missingness")
g1991pod
```

```{r data1pod0.3, echo=FALSE}
data1 <- kpodclustr::makeData(p = 2, n = 20, k = 3, sigma = 0.25, missing = 0.3, seed = 1991)
Xm1991 <- data1[[2]]
kp1991 <- kpodclustr::kpod(Xm1991,3)
g1991pod <- ggplot(data = as.data.frame(X1991), mapping = aes(x=X1991[,1],y=X1991[,2], color=factor(kp1991$cluster))) + geom_point() + theme(legend.position = "none")
g1991pod <- g1991pod + labs(x = "Feature 1", y = "Feature 2", title = "Data 1, k-POD with 30% missingness")
g1991pod
```

```{r data1pod0.5, echo=FALSE}
data1 <- kpodclustr::makeData(p = 2, n = 20, k = 3, sigma = 0.25, missing = 0.5, seed = 1991)

Xm1991 <- data1[[2]]
kp1991 <- kpodclustr::kpod(Xm1991,3)
g1991pod <- ggplot(data = as.data.frame(X1991), mapping = aes(x=X1991[,1],y=X1991[,2], color=factor(kp1991$cluster))) + geom_point() + theme(legend.position = "none")
g1991pod <- g1991pod + labs(x = "Feature 1", y = "Feature 2", title = "Data 1, k-POD with 50% missingness")
g1991pod
```